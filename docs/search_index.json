[
["clusters.html", "Chapter 5 Clusters 5.1 Overview 5.2 Cluster Managers 5.3 On-Premise Clusters 5.4 Cloud Clusters 5.5 Recap", " Chapter 5 Clusters Previous chapters focused on using Spark over a single computing instance, your personal computer. In this chapter we will introduce techniques to run Spark over multiple computing instances, also known as a computing cluster, to analyze data at scale. If you already have a Spark cluster in your organization, you could consider skipping to the next chapter, Connections, which will teach you how to connect to an existing clusters. If don’t have a cluster or are considering improvements to your existing infrastructure, this chapter will introduce some of the cluster providers available today. 5.1 Overview There are three major trends in cluster computing worth discussing: on-premise, cloud computing and kubernetes. Framing these trends over time will help us understand how they came to be, what they are and what their future might be: Figure 5.1: Google trends for on-premise (mainframe), cloud computing and kubernetes. On-premise stands for on-premise, meaning that someone, either yourself or someone in your organiation purchased physical computers that are intended to be used for cluster computing. The computers in this cluster can made of off-the-shelf hardware, meaning that someone place an order to purchase computers usually found in stores shelves or, high-performance hardware, meaning that a computing vendor provided highly customized computing hardware which also comes optimized for high-performance network connectivity, power consumption, etc. When purchasing hundreds or thousands of computing instances, it doesn’t make sense to keep them in the usual computing casing that we are all familiar with, but rather, it makes sense to stack them as efficient as possible on top of each other to minimize space and help disipate heat. This group of efficiently stacked computing instances is known as a rack. Once you have thousands or, yes, even millions of computers, you will also need many racks of computing devices and yes, you would also need significant physycal space to hosts those racks, a building that provides racks of computing instances is usually known as a Data Center. A data center is a building designated to hold many racks with many computing instances in each. At the scale of a data center, optimizing the building that holds them, their heating system, power suply, network connectivity, etc. becomes also relevant to optimize. In 2011, Facebook announced the Open Compute Project inniciative which provides a set of data center blueprints free for anyone to use. There is nothing preventing us from building our own data centers and in fact, many organizations have followed this path. For instance, Amazon started as an online book store, over the years Amazon grew to sell much more than just books and, with it’s online store growth, their data centers also grew in size. In 2002, Amazon considered selling access to virtual servers, in their data centers to the public and, in 2004, Amazon Web Services launched as a way to let anyone rent a subset of their datacenters on-demand, meaning that one did not have to purchase, configure, maintain nor teardown it’s own clusters but could rather rent them from Amazon directly. cloud computing. The on-demand compute model is what we know today as Cloud Computing. It’s a concept that evolved from Amazon Web Services providing their data centers as a service. In the cloud, the cluster you use is not owned by you and is neither in your physical building, but rather, it’s a data center owned and managed by someone else. Today, there are many cloud providers in this space ranging from Amazon, Microsoft, Google, IBM and many others. Most cloud computing platforms provide a user interface either through a web applciation and command line to request and manage resources. While the bennefits of processing data in the cloud were obvious for many years, picking a cloud provider had the unintended side-effect of locking organizations with one particular provider, making it hard to switch between provideers or back to on-premise clusters. Kubernetes, announced by Google in 2014, is an open source system for managing containerized applications across multiple hosts. In practice, it provides common infrastructure otherwise proprietary to cloud providers making it much easier to deploy across multiple cloud providers and on-premise as well. However, being a much newer paradigm than on-premise or cloud computing, it is still in it’s adoption phase but, nevertheless, promising for cluster computing in general and, specifically, for Apache Spark. 5.2 Cluster Managers In order to run Spark within a computing cluster, one needs to run something capable of initializing Spark over each compute instance, this is known as a cluster manager. The available cluster managers in Spark are: Spark Standalone, YARN, Mesos and Kubernetes. 5.2.1 Spark Standalone In Spark Standalone, Spark works on it’s own without additional software requirements since it provides it’s own cluster manager as part of the Spark installation. By completing the, Getting Started chapter, you should have a local Spark installation available, which we can use to initialize a local stanalone Spark cluster. First, retrieve the SPARK_HOME directory by running sparklyr::spark_home_dir() from R and then, from a terminal, change to the SPARK_HOME directory, start the master node and the slave nodes as follows: cd SPARK_HOME sbin/start-master.sh sbin/start-slave.sh spark://master-hostname:port Once data analysis is complete, one can simply stop all the running nodes in this local cluster by running: sbin/start-all.sh A similar approach can be followed across a real cluster by running each command over each machine in the cluster. While this approach is useful in some cases, running Spark in standalone mode can become challenging to manage since each machine needs to be configured, modified and upgraded individually which is time consuming and error-prone. Instead of installing Spark, Hadoop, etc. manually over every machine, what is known as a cluster manager is usually installed only once per machine. Once a cluster manager is installed, it will provide the tools to install additional software over each node with ease reducing installation and mantenance time. Further reading: Spark Standalone Mode 5.2.2 YARN YARN for short, or Hadoop YARN, is the resource manager introduced in 2012 to the Hadoop project. As mentioned in in the Introduction chapter, Spark was built initially to speed up computation over Hadoop; then, when Hadoop 2 was launched, it introduced YARN as a component to manage resources in the cluster, to this date, using Hadoop YARN with Apache Spark is still very common. Yarn applications can be submitted in two modeS: Yarn-Client and Yarn-Cluster. In yarn-cluster mode the driver is running remotely, while in yarn-client mode, the driver is on the machine that started the job. sparklyr supports both modes with examples available in the Connections chapter. Further reading: Running Spark on YARN 5.2.3 Mesos Figure 5.2: Mesos Landing Site. Further reading: Running Spark on Mesos 5.2.4 Kubernetes Figure 5.3: Kubernetes Landing Site. Further reading: Running Spark on Kubernetes 5.3 On-Premise Clusters As mentioned in the overview section, on-premise clusters represent a set of computing instances procured, colocated and managed by staff members from your organization. These clusters can be highly customized and controlled; however, they can also inccur significant initial expenses and maintenance costs. One can use a cluster manager in on-premise clusters as described in the previous section; however, many organizations choose to partner with companies providing additional management software, services and resources to manage software in their cluster including, but not limited to, Apache Spark. Some of the on-premise cluster providers include: Cloudera, Hortonworks and MapR to mention a few which will be briefly introduced. 5.3.1 Cloudera Cloudera, Inc. is a United States-based software company that provides Apache Hadoop and Apache Spark-based software, support and services, and training to business customers. Cloudera’s hybrid open-source Apache Hadoop distribution, CDH (Cloudera Distribution Including Apache Hadoop), targets enterprise-class deployments of that technology. Cloudera says that more than 50% of its engineering output is donated upstream to the various Apache-licensed open source projects (Apache Hive, Apache Avro, Apache HBase, and so on) that combine to form the Apache Hadoop platform. Cloudera is also a sponsor of the Apache Software Foundation. Figure 5.4: Cloudera Landing Site. 5.3.2 Hortonworks Hortonworks is a big data software company based in Santa Clara, California. The company develops, supports, and provides expertise on an expansive set of entirely open source software designed to manage data and processing for everything from IOT, to advanced analytics and machine learning. Hortonworks believes it is a data management company bridging the cloud and the datacenter. Figure 5.5: Hortonworks Landing Site. 5.3.3 MapR MapR is a business software company headquartered in Santa Clara, California. MapR provides access to a variety of data sources from a single computer cluster, including big data workloads such as Apache Hadoop and Apache Spark, a distributed file system, a multi-model database management system, and event stream processing, combining analytics in real-time with operational applications. Its technology runs on both commodity hardware and public cloud computing services. Figure 5.6: MapR Landing Site. 5.4 Cloud Clusters For those readers that don’t have a cluster yet, it is likely that you will want to choose a cloud cluster, this section will briefly mention some of the major cloud infrastructure providers as a starting point to choose the right one for you. It is worth mentioning that in a cloud service model, the compute instances are charged by the hour and times the number of instances reserved for your cluster. Since the cluster size is flexible, it is a good practice to start with small clusters and scale compute resources as needed. Even if you know in advance that a cluster of significant size will be required, starting small provides an opportunity to troubleshoot issues at a lower cost since it’s unlikely that your data analysis will run at scale flawlessly on the first try. The major providers of cloud computing infrastructure are: Amazon, Google and Microsoft that this section will briefly introduce. 5.4.1 Amazon Amazon provides cloud services through Amazon Web Services; more specifically, they provide an on-demand Spark cluster through Amazon Elastic Map Reduce or EMR for short. Figure 5.7: Amazon EMR Landing Site. 5.4.2 Google Google provides their on-demand computing services through their Google Cloud, on-demand Spark cluster are provided by Google Dataproc. Figure 5.8: Google Dataprox Landing Site. 5.4.3 Microsoft Microsoft provides cloud services thorugh Microsft Azure and Spark clusters through Azure HDInsight. Figure 5.9: Azure HDInsight Landing Site. 5.5 Recap This chapter explained the history and tradeoffs of on-premise, cloud computing and presentes kubernetes as a promising framework to provide flexibility across on-premise and interoperable cloud providers. It also introduced cluster managers as the software needed to run cluster applications covering Spark Standalone, YARN, Mesos and Kubernetes. This chapter briefly mentioned on-premise cluster providers like Cloudera, Hortonworks and MapR as well as the major cloud providers: Amazon, Google and Microsoft. While this chapter provided a solid foundation to understand current computing trends, cluster tools and providers useful to perform data science; it falls short to help those tasked with deliberately choosing a cluster manager, service provider or architecture. If you have this task assigned to you, use this chapter as a starting point to reach to many more resources to complete your understanding of the platform your organization needs. The next chapter, Connections, assumes a Spark cluster is already available to you and will focus on understanding how to connect to it from sparklyr. "]
]
